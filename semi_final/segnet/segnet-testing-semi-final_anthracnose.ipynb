{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":14171627,"sourceType":"datasetVersion","datasetId":9033189},{"sourceId":14172628,"sourceType":"datasetVersion","datasetId":8331419},{"sourceId":14211980,"sourceType":"datasetVersion","datasetId":8926183}],"dockerImageVersionId":31239,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport os\nimport tensorflow as tf\nimport cv2\nimport json\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\nprint(\"Hello world.\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-18T13:44:28.961071Z","iopub.execute_input":"2025-12-18T13:44:28.962102Z","iopub.status.idle":"2025-12-18T13:44:28.967102Z","shell.execute_reply.started":"2025-12-18T13:44:28.962066Z","shell.execute_reply":"2025-12-18T13:44:28.966033Z"}},"outputs":[{"name":"stdout","text":"Hello world.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import os\nimport json\nimport numpy as np\nimport cv2\n\ndef create_mask(json_file, image_shape):\n    if json_file is None or not os.path.exists(json_file):\n        return None\n    try:\n        with open(json_file, 'r') as f:\n            data = json.load(f)\n    except:\n        return None\n    if 'shapes' not in data or data['shapes'] is None:\n        return None\n\n    mask = np.zeros(image_shape[:2], dtype=np.uint8)\n\n    try:\n        for shape in data['shapes']:\n            points = np.array(shape.get('points', []), dtype=np.int32)\n            if len(points) > 2:\n                cv2.fillPoly(mask, [points], 255)\n    except:\n        return None\n\n    return mask\n\n\ndef find_image_file(base_name, image_path):\n    \"\"\"Find the correct image file (.jpg, .JPG, .jpeg, .JPEG, .png)\"\"\"\n    exts = [\".jpg\", \".JPG\", \".jpeg\", \".JPEG\", \".png\"]\n    for ext in exts:\n        file_path = os.path.join(image_path, base_name + ext)\n        if os.path.exists(file_path):\n            return file_path\n    return None\n\nprint(\"Hello world\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T13:44:28.968397Z","iopub.execute_input":"2025-12-18T13:44:28.968960Z","iopub.status.idle":"2025-12-18T13:44:28.991383Z","shell.execute_reply.started":"2025-12-18T13:44:28.968937Z","shell.execute_reply":"2025-12-18T13:44:28.990484Z"}},"outputs":[{"name":"stdout","text":"Hello world\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"train_images, valid_images, test_images  = [], [], []\ntrain_masks, valid_masks, test_masks = [], [] , []\ntest_images_a, test_images_b, test_images_d = [], [], []\ntest_masks_a, test_masks_b, test_masks_d = [], [], []\n\nimage_path = \"/kaggle/input/malabar-dataset/Malabar_Dataset_Original_Data/Malabar_Dataset/Anthracnose(102)\"\njson_path = \"/kaggle/input/annotated-dataset-json-files-version-2/annotated_json_files/Anthracnose(102)/affected_region\"\nsplit_file = pd.read_csv(\"/kaggle/input/malabar-dataset/anthracnose_split.csv\")\n\n\nfor i in range(0, len(split_file)):\n    used_for = split_file.iloc[i][\"used_for\"]\n    image_no = split_file.iloc[i][\"image_no\"]\n    base_name = f\"Anthracnose ({image_no})\"\n\n    json_file = os.path.join(json_path, base_name + \".json\")\n\n    # --- FIND REAL IMAGE FILE ---\n    image_file = find_image_file(base_name, image_path)\n    if image_file is None:\n        print(f\"Image missing: {base_name}\")\n        continue\n\n    image = cv2.imread(image_file)\n    if image is None:\n        print(f\"Failed to read: {image_file}\")\n        continue\n\n    mask = create_mask(json_file, image.shape)\n    if mask is None:\n        print(f\"Mask skipped: {json_file}\")\n        continue\n\n    if used_for == \"training\":\n        train_images.append(image)\n        train_masks.append(mask)\n    elif used_for == \"validation\":\n        valid_images.append(image)\n        valid_masks.append(mask)\n    else:\n        test_images.append(image)\n        test_masks.append(mask)\n        test_images_a.append(image)\n        test_masks_a.append(mask)\n\n\n\nprint(len(train_images), len(train_masks))\nprint(len(valid_images), len(valid_masks))\nprint(len(test_images), len(test_masks))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T13:44:28.992366Z","iopub.execute_input":"2025-12-18T13:44:28.992655Z","iopub.status.idle":"2025-12-18T13:44:37.272982Z","shell.execute_reply.started":"2025-12-18T13:44:28.992625Z","shell.execute_reply":"2025-12-18T13:44:37.272120Z"}},"outputs":[{"name":"stdout","text":"80 80\n10 10\n12 12\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\nimport numpy as np\n\n# Preprocess images and masks\nimage_size = (256, 256)\n\ndef preprocess_data(images, masks):\n    images_resized = [cv2.resize(img, image_size) for img in images]\n    masks_resized = [cv2.resize(mask, image_size) for mask in masks]\n    \n    images_array = np.array(images_resized) / 255.0\n    masks_array = np.array(masks_resized) / 255.0\n    \n    images_array = images_array.astype(np.float32)\n    masks_array = masks_array.astype(np.float32)\n    \n    masks_array = np.expand_dims(masks_array, axis=-1)  # Ensure correct shape\n    \n    return images_array, masks_array\n\n\nX_test, Y_test = preprocess_data(test_images, test_masks)\nprint(\"Hello world.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T13:44:37.275008Z","iopub.execute_input":"2025-12-18T13:44:37.275287Z","iopub.status.idle":"2025-12-18T13:44:37.306843Z","shell.execute_reply.started":"2025-12-18T13:44:37.275266Z","shell.execute_reply":"2025-12-18T13:44:37.306093Z"}},"outputs":[{"name":"stdout","text":"Hello world.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\nimport matplotlib.pyplot as plt\nimport cv2\nimport numpy as np\nimport os\n\n# Prediction and Mask Creation\ndef create_mask(predictions):\n    # Convert predictions to binary mask\n    predictions = (predictions > 0.5).astype(np.uint8)\n    return predictions\n\n# Load model and predict\nbest_model = load_model(\"/kaggle/input/temp-testing-dataset/Segnet_semi_final_best_model.keras\")\npredictions = best_model.predict(X_test)\n\n# Create masks from predictions\npredicted_masks = create_mask(predictions)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-18T13:44:37.307689Z","iopub.execute_input":"2025-12-18T13:44:37.307922Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\n\ndef visualize_results(images, y_test, predicted_masks):\n    for i in range(len(images)):\n        img = images[i]\n        true_mask = y_test[i].squeeze()\n        predicted_mask = predicted_masks[i].squeeze()\n\n        # Binary predicted mask\n        pred_bin = (predicted_mask > 0.5).astype(np.uint8)\n\n        # Ensure uint8 image\n        img_uint8 = (img * 255).astype(np.uint8) if img.dtype != np.uint8 else img\n\n        # ---- Red Highlight using Predicted Mask ----\n        output = img_uint8.copy()\n        alpha = 0.5\n        red_color = np.array([0, 0, 255])  # BGR red\n\n        output[pred_bin == 1] = (\n            img_uint8[pred_bin == 1] * (1 - alpha) + red_color * alpha\n        ).astype(np.uint8)\n\n        # ---- Visualization ----\n        plt.figure(figsize=(30, 5))\n\n        plt.subplot(1, 4, 1)\n        plt.imshow(cv2.cvtColor(img_uint8, cv2.COLOR_BGR2RGB))\n        plt.title('Original Image')\n        plt.axis('off')\n\n        plt.subplot(1, 4, 2)\n        plt.imshow(true_mask, cmap='gray')\n        plt.title('True Mask (Ground Truth)')\n        plt.axis('off')\n\n        plt.subplot(1, 4, 3)\n        plt.imshow(predicted_mask, cmap='gray')\n        plt.title('Predicted Mask')\n        plt.axis('off')\n\n        plt.subplot(1, 4, 4)\n        plt.imshow(cv2.cvtColor(output, cv2.COLOR_BGR2RGB))\n        plt.title('Segmented Area (Red Highlight)')\n        plt.axis('off')\n\n        plt.show()\n\nvisualize_results(X_test, Y_test, predicted_masks)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"while(True):\n    a = 5","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}